<?xml version="1.0" encoding="UTF-8"?>
<transformation>
  <info>
    <name>Incremental Load Log Start Entry</name>
    <description/>
    <extended_description/>
    <trans_version/>
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>&#47;</directory>
    <parameters>
    </parameters>
    <log>
<trans-log-table><connection/>
<schema/>
<table/>
<size_limit_lines/>
<interval/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STATUS</id><enabled>Y</enabled><name>STATUS</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name><subject/></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name><subject/></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name><subject/></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name><subject/></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name><subject/></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name><subject/></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>STARTDATE</id><enabled>Y</enabled><name>STARTDATE</name></field><field><id>ENDDATE</id><enabled>Y</enabled><name>ENDDATE</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>DEPDATE</id><enabled>Y</enabled><name>DEPDATE</name></field><field><id>REPLAYDATE</id><enabled>Y</enabled><name>REPLAYDATE</name></field><field><id>LOG_FIELD</id><enabled>N</enabled><name>LOG_FIELD</name></field></trans-log-table>
<perf-log-table><connection/>
<schema/>
<table/>
<interval/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>SEQ_NR</id><enabled>Y</enabled><name>SEQ_NR</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>INPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>INPUT_BUFFER_ROWS</name></field><field><id>OUTPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>OUTPUT_BUFFER_ROWS</name></field></perf-log-table>
<channel-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>LOGGING_OBJECT_TYPE</id><enabled>Y</enabled><name>LOGGING_OBJECT_TYPE</name></field><field><id>OBJECT_NAME</id><enabled>Y</enabled><name>OBJECT_NAME</name></field><field><id>OBJECT_COPY</id><enabled>Y</enabled><name>OBJECT_COPY</name></field><field><id>REPOSITORY_DIRECTORY</id><enabled>Y</enabled><name>REPOSITORY_DIRECTORY</name></field><field><id>FILENAME</id><enabled>Y</enabled><name>FILENAME</name></field><field><id>OBJECT_ID</id><enabled>Y</enabled><name>OBJECT_ID</name></field><field><id>OBJECT_REVISION</id><enabled>Y</enabled><name>OBJECT_REVISION</name></field><field><id>PARENT_CHANNEL_ID</id><enabled>Y</enabled><name>PARENT_CHANNEL_ID</name></field><field><id>ROOT_CHANNEL_ID</id><enabled>Y</enabled><name>ROOT_CHANNEL_ID</name></field></channel-log-table>
<step-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>LOG_FIELD</id><enabled>N</enabled><name>LOG_FIELD</name></field></step-log-table>
    </log>
    <maxdate>
      <connection/>
      <table/>
      <field/>
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>1000</size_rowset>
    <sleep_time_empty>1</sleep_time_empty>
    <sleep_time_full>1</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>5000</feedback_size>
    <using_thread_priorities>N</using_thread_priorities>
    <shared_objects_file/>
    <capture_step_performance>N</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit/>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
  <modified_user>-</modified_user>
  <modified_date>2007&#47;06&#47;07 12:04:59.781</modified_date>
  </info>
  <notepads>
  </notepads>
  <connection>
    <name>DestinationDB</name>
    <server/>
    <type>MYSQL</type>
    <access>JNDI</access>
    <database>DestinationDB</database>
    <port>1521</port>
    <username/>
    <password>Encrypted </password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>EXTRA_OPTION_MYSQL.defaultFetchSize</code><attribute>500</attribute></attribute>
      <attribute><code>EXTRA_OPTION_MYSQL.useCursorFetch</code><attribute>true</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>1521</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>STREAM_RESULTS</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>N</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
  <connection>
    <name>wcm</name>
    <server>localhost</server>
    <type>MYSQL</type>
    <access>Native</access>
    <database>wcm</database>
    <port>3306</port>
    <username>root</username>
    <password>Encrypted 2be98afc86aa7f2e4cb79ce7dc781bed6</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>EXTRA_OPTION_MYSQL.defaultFetchSize</code><attribute>500</attribute></attribute>
      <attribute><code>EXTRA_OPTION_MYSQL.useCursorFetch</code><attribute>true</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>3306</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>STREAM_RESULTS</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>N</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
  <order>
  <hop> <from>Set ETL start time</from><to>Log Start</to><enabled>Y</enabled> </hop>  <hop> <from>Confirm Okay to Proceed</from><to>Set ETL start time</to><enabled>Y</enabled> </hop>  <hop> <from>Set ETL name</from><to>Set ETL Job and Incremental Complete Up To Date</to><enabled>Y</enabled> </hop>  <hop> <from>Set ETL Job and Incremental Complete Up To Date</from><to>Confirm Okay to Proceed</to><enabled>Y</enabled> </hop>  </order>
  <step>
    <name>Confirm Okay to Proceed</name>
    <type>ScriptValueMod</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <compatible>N</compatible>
    <jsScripts>      <jsScript>        <jsScript_type>0</jsScript_type>
        <jsScript_name>Script 1</jsScript_name>
        <jsScript_script>var fail_reason = &quot;&quot;;
var DBConnection = &quot;DestinationDB&quot;;
var queryCount;


var sql = &quot;select count(*) from stg_etl_run_history where etl_job = &apos;Initial Entry&apos; &quot;;
var sqlResults = fireToDB(DBConnection, sql);
queryCount = parseInt(sqlResults[0][0]);

if (queryCount &gt; 0)
{
	fail_reason = &quot;The Data Warehouse has Previously Been Built using the Full Reload Functionality - Can&apos;t run an incremental ETL job over it.  Either Delete the Current Data Warehouse Database or Configure a Different DestinationDB Database Name.&quot;;
}


if (fail_reason == &quot;&quot;)
{
	sql = &quot;select count(*) from stg_etl_run_history where etl_end_time is null&quot;;
	sqlResults = fireToDB(DBConnection, sql);
	queryCount = parseInt(sqlResults[0][0]);

	if (queryCount &gt; 0)
	{
		fail_reason = &quot;A Previous Incremental Build Did Not Successfully Complete.&quot;;
	}
}


if (fail_reason == &quot;&quot;)
{

		sql = &quot;select ifnull(max(etl_complete_to_date), &apos;1900-01-01&apos;) from stg_etl_run_history&quot;;
		sqlResults = fireToDB(DBConnection, sql);
		var max_etl_complete_to_date = sqlResults[0][0];


		sql = &quot;select if(ifnull(max(etl_complete_to_date), &apos;1900-01-01&apos;) &gt;= &apos;&quot; + etl_complete_to_date + &quot;&apos;, 1, 0) from stg_etl_run_history&quot;;
		sqlResults = fireToDB(DBConnection, sql);
		queryCount = parseInt(sqlResults[0][0]);

		if (queryCount &gt; 0)
		{
			fail_reason = &quot;Invalid Run - &quot; + etl_complete_to_date + &quot;: Data is Already Built Upto End: &quot; + max_etl_complete_to_date;
		}
}


if (fail_reason == &quot;&quot;)
{


		sql = &quot;select if(curdate() &lt;= &apos;&quot; + etl_complete_to_date + &quot;&apos;, 1, 0) &quot;;
		sqlResults = fireToDB(DBConnection, sql);
		queryCount = parseInt(sqlResults[0][0]);

		if (queryCount &gt; 0)
		{
			fail_reason = &quot;Invalid Run - &quot; + etl_complete_to_date + &quot;: You Can&apos;t Build for Dates from Today Onwards&quot;;
		}
}

if (fail_reason &gt; &quot;&quot;)
{
	writeToLog(&quot;e&quot;, fail_reason);
	trans_Status = ERROR_TRANSFORMATION;
}
</jsScript_script>
      </jsScript>    </jsScripts>    <fields>    </fields>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>476</xloc>
      <yloc>57</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Log Start</name>
    <type>TableOutput</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>DestinationDB</connection>
    <schema/>
    <table>stg_etl_run_history</table>
    <commit>1000</commit>
    <truncate>N</truncate>
    <ignore_errors>N</ignore_errors>
    <use_batch>Y</use_batch>
    <specify_fields>Y</specify_fields>
    <partitioning_enabled>N</partitioning_enabled>
    <partitioning_field/>
    <partitioning_daily>N</partitioning_daily>
    <partitioning_monthly>Y</partitioning_monthly>
    <tablename_in_field>N</tablename_in_field>
    <tablename_field/>
    <tablename_in_table>Y</tablename_in_table>
    <return_keys>N</return_keys>
    <return_field/>
    <fields>
        <field>
          <column_name>etl_name</column_name>
          <stream_name>etl_name</stream_name>
        </field>
        <field>
          <column_name>etl_job</column_name>
          <stream_name>etl_job</stream_name>
        </field>
        <field>
          <column_name>etl_complete_to_date</column_name>
          <stream_name>etl_complete_to_date</stream_name>
        </field>
        <field>
          <column_name>etl_start_time</column_name>
          <stream_name>etl_start_time</stream_name>
        </field>
    </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>811</xloc>
      <yloc>58</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Set ETL Job and Incremental Complete Up To Date</name>
    <type>ScriptValueMod</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <compatible>N</compatible>
    <jsScripts>      <jsScript>        <jsScript_type>0</jsScript_type>
        <jsScript_name>Script 1</jsScript_name>
        <jsScript_script>
var etl_job = getVariable(&quot;etl_job&quot;,  &quot;Incremental Entry&quot;);


var etl_complete_to_date = getVariable(&quot;etl_complete_to_date&quot;,  &quot;&quot;);


if (etl_complete_to_date == null || etl_complete_to_date &lt;= &quot;&quot;)
{
	var DBConnection = &quot;DestinationDB&quot;;
	var sql = &quot;select date_sub(curdate(), interval 1 day) as default_date&quot;;
	var sqlResults = fireToDB(DBConnection, sql);
	etl_complete_to_date = sqlResults[0][0]; 
	setVariable(&quot;etl_complete_to_date&quot;,etl_complete_to_date, &quot;r&quot;);
}

</jsScript_script>
      </jsScript>    </jsScripts>    <fields>      <field>        <name>etl_job</name>
        <rename>etl_job</rename>
        <type>String</type>
        <length>50</length>
        <precision>-1</precision>
        <replace>N</replace>
      </field>      <field>        <name>etl_complete_to_date</name>
        <rename>etl_complete_to_date</rename>
        <type>String</type>
        <length>20</length>
        <precision>-1</precision>
        <replace>N</replace>
      </field>    </fields>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>256</xloc>
      <yloc>126</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Set ETL name</name>
    <type>RowGenerator</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>
      <field>
        <name>etl_name</name>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <nullif>Main</nullif>
        <length>50</length>
        <precision>-1</precision>
      </field>
    </fields>
    <limit>1</limit>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>59</xloc>
      <yloc>58</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Set ETL start time</name>
    <type>DBJoin</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>DestinationDB</connection>
    <rowlimit>1</rowlimit>
    <sql>select now() as etl_start_time </sql>
    <outer_join>N</outer_join>
    <replace_vars>N</replace_vars>
    <parameter>
    </parameter>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>645</xloc>
      <yloc>127</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step_error_handling>
  </step_error_handling>
   <slave-step-copy-partition-distribution>
</slave-step-copy-partition-distribution>
   <slave_transformation>N</slave_transformation>
</transformation>
